{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\python311\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: pydub in c:\\python311\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\python311\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai requests pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import datetime\n",
    "import requests\n",
    "from google.colab import files\n",
    "from requests.exceptions import RequestException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mp3(url, file_path):\n",
    "    try:\n",
    "        # Send a HTTP request to the URL of the MP3 file\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        # Open the file in write mode to download the MP3 file\n",
    "        with open(file_path, 'wb') as audio:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:  # filter out keep-alive new chunks\n",
    "                    audio.write(chunk)\n",
    "        print(f\"Downloaded successfully: {file_path}\")\n",
    "        return file_path\n",
    "    except RequestException as e:\n",
    "        print(f\"Error during the request of {url}: {str(e)}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error during the download of {url}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio file using Whisper API\n",
    "def transcribe_audio_whisper_api(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            transcription = openai.Audio.transcribe(\"whisper-1\", file)\n",
    "        return transcription\n",
    "    except Exception as e:\n",
    "        print(f\"{datetime.datetime.now()} [ERROR]: Error in transcription: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze emotion from text using OpenAI GPT model\n",
    "def analyze_emotion(text):\n",
    "    try:\n",
    "        content = f\"What emotion is the following text expressing?\\n{text}\"\n",
    "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": content}]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\",\n",
    "            messages=messages,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        emotion = response['choices'][0]['message']['content']\n",
    "        return emotion.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"{datetime.datetime.now()} [ERROR]: Error in emotion analysis: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize text using OpenAI Chat model\n",
    "def summarize_text(text, style):\n",
    "    try:\n",
    "        # Using the chat endpoint\n",
    "        if style == \"1\":\n",
    "            content = f\"Summarize the following text in bullet points, ordered by importance:\\n{text}\"\n",
    "        elif style == \"2\":\n",
    "            content = f\"Summarize the following text in a short paragraph of 4 to 5 lines:\\n{text}\"\n",
    "        else:\n",
    "            content = f\"Summarize the following text concisely:\\n{text}\"\n",
    "\n",
    "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": content}]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\",\n",
    "            messages=messages,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        summary = response['choices'][0]['message']['content']\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"{datetime.datetime.now()} [ERROR]: Error in summarization: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input for source of MP3 file\n",
    "print(\"Select the source of MP3 file:\")\n",
    "print(\"1 - Upload File\")\n",
    "print(\"2 - Insert MP3 Link\")\n",
    "source = input(\"Enter 1 or 2: \")\n",
    "\n",
    "file_path = None\n",
    "if source == \"1\":\n",
    "    # Upload the MP3 file\n",
    "    uploaded = files.upload()\n",
    "    for mp3_filename in uploaded.keys():\n",
    "        print(f\"{datetime.datetime.now()} [INFO]: User uploaded file '{mp3_filename}'\")\n",
    "        file_path = mp3_filename\n",
    "elif source == \"2\":\n",
    "    # Download the MP3 file from the given link\n",
    "    url = input(\"Enter the MP3 link: \")\n",
    "    file_path = \"audio.mp3\"  # you can set to any path you want\n",
    "    file_path = download_mp3(url, file_path)\n",
    "else:\n",
    "    print(\"Invalid option selected. Please select either 1 or 2.\")\n",
    "\n",
    "if file_path:\n",
    "    # Transcribe the audio using Whisper API\n",
    "    print(f\"{datetime.datetime.now()} [INFO]: Transcribing audio...\")\n",
    "    transcription = transcribe_audio_whisper_api(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # User input for summarization style\n",
    "    print(\"Select summarization style:\")\n",
    "    print(\"1 - Bullet Points\")\n",
    "    print(\"2 - Short Paragraph\")\n",
    "    print(\"3 - Concise\")\n",
    "    style = input(\"Enter 1, 2, or 3: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Analyze emotion from the transcription using OpenAI GPT model\n",
    "    if transcription:\n",
    "        print(f\"{datetime.datetime.now()} [INFO]: Analyzing emotion...\")\n",
    "        emotion = analyze_emotion(transcription)\n",
    "        print(f\"{datetime.datetime.now()} [INFO]: Emotion: {emotion}\")\n",
    "\n",
    "        # Summarize the transcription using OpenAI Chat model\n",
    "        print(f\"{datetime.datetime.now()} [INFO]: Summarizing text...\")\n",
    "        summary = summarize_text(transcription, style)\n",
    "        print(f\"{datetime.datetime.now()} [INFO]: Summary: {summary}\")\n",
    "\n",
    "        # Download the summary as a text file\n",
    "        with open('summary.txt', 'w') as f:\n",
    "            f.write(f\"Emotion: {emotion}\\n\\n\")\n",
    "            f.write(summary)\n",
    "        files.download('summary.txt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
